{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic search with sentence embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reset -f \n",
    "import pdb\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from datasets import load_dataset, Dataset\n",
    "\n",
    "from QuranCorpus import QuranCorpus\n",
    "\n",
    "%matplotlib inline\n",
    "pd.set_option('max_colwidth', 400)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "quran_corpus = QuranCorpus(is_remove_basamal=True)\n",
    "quran_corpus.read_in_quran()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6235 6235 6235\n"
     ]
    }
   ],
   "source": [
    "print(len(quran_corpus.documents_by_verse), len(quran_corpus.i_surah), len(quran_corpus.i_verse))\n",
    "df0 = pd.DataFrame({'text': quran_corpus.documents_by_verse, 'surah': quran_corpus.i_surah, 'verse': quran_corpus.i_verse})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Dataset.from_pandas(df0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'praise be to allah, lord of the worlds.', 'surah': 1, 'verse': 2}"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create embeddings\n",
    "\n",
    "Instructions: https://www.sbert.net/examples/applications/semantic-search/README.html#symmetric-vs-asymmetric-semantic-search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_ckpt = \"sentence-transformers/multi-qa-mpnet-base-dot-v1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = AutoModel.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MPNetModel(\n",
       "  (embeddings): MPNetEmbeddings(\n",
       "    (word_embeddings): Embedding(30527, 768, padding_idx=1)\n",
       "    (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): MPNetEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x MPNetLayer(\n",
       "        (attention): MPNetAttention(\n",
       "          (attn): MPNetSelfAttention(\n",
       "            (q): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (k): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (v): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (o): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (intermediate): MPNetIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): MPNetOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (relative_attention_bias): Embedding(32, 12)\n",
       "  )\n",
       "  (pooler): MPNetPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CLS pooling\n",
    "Pooling is the process of converting a sequence of embeddings into a sentence embedding is called “pooling”.  \n",
    "One way is using CLS pooling: to collect the last hidden state for the special [CLS] token  \n",
    " - CLS token: Append a special <CLS> token to the start of every sequence. This special token is meant to capture the sequence-level information. \n",
    " - During the training process, some sentence-level classification (like next sewntence prediction) task based on this CLS embedding will tune the CLS token representation via backpropagation.  \n",
    "  \n",
    "From [article of pooling methods](https://blog.ml6.eu/the-art-of-pooling-embeddings-c56575114cf8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cls_pooling(model_output):\n",
    "    return model_output.last_hidden_state[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text_list):\n",
    "    encoded_input = tokenizer(\n",
    "        text_list, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    )\n",
    "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "    model_output = model(**encoded_input)\n",
    "    return cls_pooling(model_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "praise be to allah, lord of the worlds. \n",
      " (1, 768)\n"
     ]
    }
   ],
   "source": [
    "# Compute one doc\n",
    "text_input = data['text'][0]\n",
    "embedding = get_embeddings(text_input)\n",
    "# Detach from the computational graph, copy it to host memory, and then convert to numpy array\n",
    "embedding = embedding.detach().cpu().numpy()\n",
    "\n",
    "print(text_input, '\\n', embedding.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73048685bf02481896252bfde61be211",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6235 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute everything\n",
    "embeddings_dataset = data.map(\n",
    "    lambda x: {'embeddings': get_embeddings(x['text']).detach().cpu().numpy()[0]}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering by Surah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe = embeddings_dataset.to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hierachichal clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "\n",
    "def get_cluster_labels(x):\n",
    "    n_clusters = int(np.log2(len(x)))\n",
    "    clustering = AgglomerativeClustering(n_clusters=n_clusters)  # Specify the number of clusters\n",
    "    # Fit the model to your data\n",
    "    clustering.fit(np.stack(x.values))\n",
    "    # Get the cluster labels for each data point\n",
    "    return clustering.labels_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe['topic'] = dfe.groupby('surah')['embeddings'].transform(get_cluster_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Eucleadian distance to find topic transition\n",
    "https://datascience.stackexchange.com/questions/73151/how-to-identify-topic-transition-in-consecutive-sentences-using-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe['previous_emb'] = dfe['embeddings'].shift(1)\n",
    "dfe['dist_eu'] = (dfe['embeddings'] - dfe['previous_emb']).apply(np.linalg.norm)\n",
    "dfe.loc[0, 'dist_eu'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_threshold = 6.0\n",
    "dfe['is_over_threshold'] = (dfe['dist_eu'] > dist_threshold).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfe['topic_group'] = dfe['is_over_threshold'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>topic_group</th>\n",
       "      <th>surah</th>\n",
       "      <th>verse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6225</th>\n",
       "      <td>from the evil of what he created.</td>\n",
       "      <td>4103</td>\n",
       "      <td>113</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6226</th>\n",
       "      <td>and from the evil of the darkness as it gathers.</td>\n",
       "      <td>4103</td>\n",
       "      <td>113</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6227</th>\n",
       "      <td>and from the evil of those who practice sorcery.</td>\n",
       "      <td>4103</td>\n",
       "      <td>113</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6228</th>\n",
       "      <td>and from the evil of an envious when he envies.</td>\n",
       "      <td>4103</td>\n",
       "      <td>113</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6229</th>\n",
       "      <td>say, i seek refuge in the lord of mankind.</td>\n",
       "      <td>4104</td>\n",
       "      <td>114</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6230</th>\n",
       "      <td>the king of mankind.</td>\n",
       "      <td>4105</td>\n",
       "      <td>114</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6231</th>\n",
       "      <td>the god of mankind.</td>\n",
       "      <td>4105</td>\n",
       "      <td>114</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6232</th>\n",
       "      <td>from the evil of the sneaky whisperer.</td>\n",
       "      <td>4106</td>\n",
       "      <td>114</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6233</th>\n",
       "      <td>who whispers into the hearts of people.</td>\n",
       "      <td>4107</td>\n",
       "      <td>114</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6234</th>\n",
       "      <td>from among jinn and among people.</td>\n",
       "      <td>4108</td>\n",
       "      <td>114</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  topic_group  surah  \\\n",
       "6225                 from the evil of what he created.         4103    113   \n",
       "6226  and from the evil of the darkness as it gathers.         4103    113   \n",
       "6227  and from the evil of those who practice sorcery.         4103    113   \n",
       "6228   and from the evil of an envious when he envies.         4103    113   \n",
       "6229        say, i seek refuge in the lord of mankind.         4104    114   \n",
       "6230                              the king of mankind.         4105    114   \n",
       "6231                               the god of mankind.         4105    114   \n",
       "6232            from the evil of the sneaky whisperer.         4106    114   \n",
       "6233           who whispers into the hearts of people.         4107    114   \n",
       "6234                 from among jinn and among people.         4108    114   \n",
       "\n",
       "      verse  \n",
       "6225      3  \n",
       "6226      4  \n",
       "6227      5  \n",
       "6228      6  \n",
       "6229      2  \n",
       "6230      3  \n",
       "6231      4  \n",
       "6232      5  \n",
       "6233      6  \n",
       "6234      7  "
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfe[['text', 'topic_group', 'surah', 'verse']].tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FAISS similarity search\n",
    "Using [FAISS](https://faiss.ai/) for efficient similarity search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7db8319b6040b19dc73595c4c19197",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'surah', 'verse', 'embeddings'],\n",
       "    num_rows: 6348\n",
       "})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install faiss-cpu\n",
    "embeddings_dataset.add_faiss_index(column=\"embeddings\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = 'What is the story of yusuf'\n",
    "question_embedding = get_embeddings([question]).cpu().detach().numpy()\n",
    "scores, samples = embeddings_dataset.get_nearest_examples(\n",
    "    \"embeddings\", question_embedding, k=5\n",
    ")\n",
    "samples_df = pd.DataFrame.from_dict(samples)\n",
    "samples_df[\"scores\"] = scores\n",
    "samples_df.sort_values(\"scores\", ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: i am to you a faithful messenger.\n",
      "Context: \n",
      "their brother noah said to them, do you not fear?\n",
      "i am to you a faithful messenger.\n",
      "so fear allah, and obey me.\n",
      "i ask of you no payment for this. my payment is only from the lord of the worlds.\n",
      "SCORE: 35.835548400878906\n",
      "Surah:Verse: 26:108\n",
      "==================================================\n",
      "\n",
      "Text: i am to you a faithful messenger.\n",
      "Context: \n",
      "when their brother hud said to them, do you not fear?\n",
      "i am to you a faithful messenger.\n",
      "so fear allah, and obey me.\n",
      "i ask of you no payment for this. my payment is only from the lord of the worlds.\n",
      "SCORE: 35.835548400878906\n",
      "Surah:Verse: 26:126\n",
      "==================================================\n",
      "\n",
      "Text: i am to you a faithful messenger.\n",
      "Context: \n",
      "when their brother saleh said to them, do you not fear?\n",
      "i am to you a faithful messenger.\n",
      "so fear allah, and obey me.\n",
      "i ask of you no payment for it. my payment is only from the lord of the worlds.\n",
      "SCORE: 35.835548400878906\n",
      "Surah:Verse: 26:144\n",
      "==================================================\n",
      "\n",
      "Text: i am to you a faithful messenger.\n",
      "Context: \n",
      "when their brother lot said to them, do you not fear?\n",
      "i am to you a faithful messenger.\n",
      "so fear allah, and obey me.\n",
      "i ask of you no payment for it. my payment is only from the lord of the worlds.\n",
      "SCORE: 35.835548400878906\n",
      "Surah:Verse: 26:163\n",
      "==================================================\n",
      "\n",
      "Text: i am to you a trustworthy messenger.\n",
      "Context: \n",
      "when shuaib said to them, do you not fear?\n",
      "i am to you a trustworthy messenger.\n",
      "so fear allah, and obey me.\n",
      "i ask of you no payment for it. my payment is only from the lord of the worlds.\n",
      "SCORE: 34.60725784301758\n",
      "Surah:Verse: 26:179\n",
      "==================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "backslash_char = '\\n'\n",
    "for _, row in samples_df.iterrows():\n",
    "    print(f\"Text: {row.text}\")\n",
    "    print(f\"Context: {backslash_char}{df0[(df0['surah'] == row.surah) & (df0['verse'].isin(list(range(max(0, row.verse - 1), row.verse + 3))))]['text'].str.cat(sep=backslash_char)}\")\n",
    "    print(f\"SCORE: {row.scores}\")\n",
    "    print(f\"Surah:Verse: {row.surah}:{row.verse}\")\n",
    "    print(\"=\" * 50)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next: Get embedding of groups of sentences \n",
    "Concat N=4 sentences and get embedding accordingly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
